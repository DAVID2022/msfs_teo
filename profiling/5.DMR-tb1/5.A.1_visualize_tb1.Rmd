---
title: "Tb1 DMR region"
output: html_notebook
author: Jinliang Yang
---


```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
knitr::opts_knit$set(root.dir=normalizePath('../../')) 
#library(tidyverse)
```


# Prepare bimark Genome

Teosinte lines:
Palmar Chico

# Find the landrace ID and their origins

```{r}
lr <- read.csv("data/landraces_ordering_04092018.csv")
```

On server:

```{r}
lr <- read.csv("data/landraces_ordering_04092018.csv")
```


### Use Google API to find the location and plot them


```{r}
### step two: google API

# install.packages("RJSONIO", repos="http://cran.rstudio.com/")
library("RJSONIO")
source("lib/modified_geocode.R.txt")
#source("lib/googleloc.R")
#assignInNamespace("geocode", geocode, ns="ggmap") 
#detach("package:ggmap", unload=TRUE)

googleloc <- function(df, google_api_key="AIzaSyA8zz", outcache, outtxt){
    ### df: [data.frame] with user id and user reported location
    ### google_api_key:  use your own google AGP key, https://console.developers.google.com/
    
    ### search location using google API
    geocode_apply <- function(x){
        geocode(x, source = "google", output = "all", override_limit = TRUE,
                api_key=google_api_key)
    }
    
    geocode_results <- sapply(as.character(df$loc), geocode_apply, simplify = F)
    
    message(sprintf("###>>> [googleloc]: find location for %s users", length(geocode_results)))
    
    ### Step Three: clearning results
    source("lib/data_cleaning.R")
    out <- loc_cleaning(geocode_results)
    
    if(!is.null(outcache)){
        save("geocode_results", file=outcache)
    }
    if(!is.null(outcache)){
        write.table(out, outtxt, sep="\t", row.names=FALSE)
    }
    
    return(geocode_results)
}


### read in the data from step one
df <- read.delim("data/user_with_address.txt")

### use your own google AGP key, find it here: https://console.developers.google.com/
### it only allows up to 2500 free search per day
res1 <- googleloc(df[1:1000,], google_api_key=mykey, 
                  outcache="cache/api_res1-1000.RData", 
                  outtxt="data/res1-1000.txt")

res2 <- googleloc(df[1001:3500,], google_api_key=mykey, 
                  outcache="cache/api_res1001-3500.RData", 
                  outtxt="data/res1001-3500.txt")


# 15 mins 900 max
### use your own google AGP key, https://console.developers.google.com/
res <- googleloc(df[1001:3500, ], google_api_key=mykey)

geocode_results <- res
length(geocode_results)
### Step Three: clearning results
source("lib/data_cleaning.R")
out <- loc_cleaning(geocode_results=res)

save("res", file="cache/api_res1001-3500.RData")
write.table(out, "data/res1001-3500.txt", sep="\t", row.names=FALSE)


```



```{r, eval=FALSE}
idtab <- read.csv("data/teo20_ids.csv")
idtab$idchar <- gsub("-", "", idtab$idchar)
idtab$pid <- paste0("JR", idtab$plate)

#####################################################################################################
# put fasta into seperate folders
f <- list.files(path="largedata/pgenome", pattern="fasta", full.names = TRUE)
df <- data.frame(dir=f, file=f)
df$dir <- gsub(".fasta", "", df$dir)
df$to <- paste0(df$dir, gsub(".*pgenome", "", df$file))
for(i in 1:nrow(df)){
  dir.create(df$dir[i])
  file.rename(as.character(df$file[i]), as.character(df$to[i]))
}


########## preparing genome
for(i in 1:20){
    shid <- paste0("slurm-script/run_pg", i, ".sh")
    cmd1 <- paste0("bismark_genome_preparation --bowtie2 largedata/pgenome/", i)
    cat(cmd1, file=shid, sep="\n", append=FALSE)
}    


## load bismark/0.14

library("huskeR")
cmd <- c("module load bismark", "module load bowtie/2.2", "sh slurm-script/run_pg$SLURM_ARRAY_TASK_ID.sh")
set_array_job(shid="slurm-script/run_pg.sh", shcode=cmd,
              arrayjobs="1-20", wd=NULL, jobid="pgjob", email="yangjl0930@gmail.com",
              run = c(FALSE, "jclarke", "2", "10G", "8:00:00"))


```


# Mapping

```{r, eval=FALSE}
library(huskeR)

idtab <- read.csv("data/teo20_ids.csv")
idtab$idchar <- gsub("-", "", idtab$idchar)
idtab$pid <- paste0("JR", idtab$plate)

########### Note, move fq files to /group/jrigrp7
########### alignment
fq1 <- list.files(path="/lustre/work/jyanglab/jyang21/hugedata/wgbs_fq", pattern="R1_trimmed.fastq.gz$", full.names = TRUE)
fq2 <- list.files(path="/lustre/work/jyanglab/jyang21/hugedata/wgbs_fq", pattern="R2_trimmed.fastq.gz$", full.names = TRUE)

#fq1 <- fq1[3:20]
#fq2 <- fq2[3:20]
#bamfiles <- list.files(path="/group/jrigrp4/BS_teo20/WGBS/BSM", pattern="bam$", full.names = TRUE)
### note: for alignment, "bam" col should not be present.
inputdf <- data.frame(fq1 = fq1,  fq2 = fq2, outbase = gsub(".*/|_.*", "", fq1), out2=gsub(".*/|_.*", "", fq2))

if(sum(as.character(inputdf$outbase) != as.character(inputdf$out2)) > 0  ){stop("!!! PE not right !!!")}

inputdf <- merge(inputdf, idtab[, c("idchar", "pid")], by.x="outbase", by.y="pid")
inputdf$genome <- paste0("/project/jyanglab/jyang21/projects/msfs_teo/largedata/pgenome/", inputdf$idchar)

### AGPv4
run_bismark(inputdf, genome = NULL,
       outdir = "/lustre/work/jyanglab/jyang21/hugedata/wgbs_align", N = 1, align = TRUE,
       email = "yangjl0930@gmail.com", runinfo = c(TRUE, "jclarke", 5, "20G", "100:00:00"))

```



